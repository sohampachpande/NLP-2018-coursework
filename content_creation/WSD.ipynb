{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation\n",
    "## Lesk, Walker and Random Walk\n",
    "\n",
    "### This post describes the concept of Word Sense, Word Sense Disambiguation and some of the techniques for Word Sense Disambiguation in Pythonic way!\n",
    "\n",
    "Let us start by importing nltk and its functions. nltk is an opensource natural language toolkit for analysis of Human languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import networkx as nx # for graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Word Sense?\n",
    "Words often have multiple interpretation depending on the use case i.e the context.\n",
    "These interpretations are referred as the Senses.\n",
    "\n",
    "#### Wordnet is machine readable lexical database which has infomation about senses and their properties. \n",
    "#### We use wordnet for lexical information regarding words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Senses of the word 'bank' is 18\n",
      "\n",
      "The different Senses of the word 'bank' are\n",
      "\n",
      "bank.n.01  :  sloping land (especially the slope beside a body of water)\n",
      "depository_financial_institution.n.01  :  a financial institution that accepts deposits and channels the money into lending activities\n",
      "bank.n.03  :  a long ridge or pile\n",
      "bank.n.04  :  an arrangement of similar objects in a row or in tiers\n",
      "bank.n.05  :  a supply or stock held in reserve for future use (especially in emergencies)\n",
      "bank.n.06  :  the funds held by a gambling house or the dealer in some gambling games\n",
      "bank.n.07  :  a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "savings_bank.n.02  :  a container (usually with a slot in the top) for keeping money at home\n",
      "bank.n.09  :  a building in which the business of banking transacted\n",
      "bank.n.10  :  a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "bank.v.01  :  tip laterally\n",
      "bank.v.02  :  enclose with a bank\n",
      "bank.v.03  :  do business with a bank or keep an account at a bank\n",
      "bank.v.04  :  act as the banker in a game or in gambling\n",
      "bank.v.05  :  be in the banking business\n",
      "deposit.v.02  :  put into a bank account\n",
      "bank.v.07  :  cover with ashes so to control the rate of burning\n",
      "trust.v.01  :  have confidence or faith in\n"
     ]
    }
   ],
   "source": [
    "example_word = \"bank\"\n",
    "\n",
    "synset_ = wn.synsets(example_word)\n",
    "print(\"No of Senses of the word '{}' is {}\\n\".format(example_word, len(synset_)))\n",
    "\n",
    "print(\"The different Senses of the word '{}' are\\n\".format(example_word))\n",
    "for ws in synset_:\n",
    "    print(ws.name(), \" : \", ws.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the confusion about?\n",
    "Often the correct word sense is not known. The sense depend on the context words. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Soham gets interest on his money from bank\"\n",
    "ambiguous_word = \"bank\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the word \"bank\" is ambiguous. It can have any of the 18 senses for the word \"bank\".\n",
    "It can be either represent sloping edge of land or a financial institution.\n",
    "\n",
    "#### In this notebook, three algorithms are described to find out the correct sense of a particular word in sentences.\n",
    "The three algorithms are :\n",
    "1. Lesk's Algorithm\n",
    "2. Random Walk\n",
    "3. Modified variant of Walker's Algorithm for Untagged data without thesaurus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the input\n",
    "\n",
    "Lesk Algorithm uses a machine readable dictionary to get gloss of multiple senses of the input words.\n",
    "\n",
    "Thus it is essential that the input sentence should be in properly lemmatized form to get proper gloss. \n",
    "The stopwords also don't add any relevant semantic information to the sentence and thus they are removed as well.\n",
    "\n",
    "Therefore we begin by defining a function to process input sentence in order to remove stopwords & lemmatize words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(sentence, porterstemmer = False):\n",
    "    processed_sent = []\n",
    "    # tokenize words of the sentence\n",
    "    words = word_tokenize(sentence)\n",
    "    # Lemmatize words to get their root form\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Get stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    # Remove stopwards and add lemmatized root form of words\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "                if porterstemmer:\n",
    "                    w = PorterStemmer().stem(w)\n",
    "                processed_sent.append(lemmatizer.lemmatize(w))\n",
    "    return processed_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Context bag consisting of all senses of the context words\n",
    "\n",
    "Gloss is description of a particular sense of any word. Gloss is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Gloss i.e. definition for a sense is:\n",
      "\n",
      "The gloss for sense bank.n.10 is :\n",
      "a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n"
     ]
    }
   ],
   "source": [
    "example_gloss = \"bank.n.10\"\n",
    "gloss_ = wn.synset(example_gloss)\n",
    "print(\"Example Gloss i.e. definition for a sense is:\\n\")\n",
    "print(\"The gloss for sense {} is :\\n{}\".format(gloss_.name(), gloss_.definition()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all sense glosses i.e definition for all words other than ambiguous word from the given sentence\n",
    "Concatenate them to form the context bag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lesk_context_bag(context_sentence, word):\n",
    "    context_bag_list = []\n",
    "    context_sentence.remove(word)\n",
    "    for w in context_sentence:\n",
    "        for syn in wn.synsets(w):\n",
    "            gloss = pre_process(str(syn.definition()))\n",
    "            for w_g in gloss:\n",
    "                context_bag_list.append(w_g)\n",
    "    return context_bag_list\n",
    "\n",
    "# lesk_context_bag(sent, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Lesk score for each Sense of the Ambiguous word\n",
    "\n",
    "Get all possible senses for the ambiguous word.\n",
    "Find Lesk score for each sense by finding number of times the words in the word sense gloss(definition) occur in the context bag. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lesk_score(context_sentence, word):\n",
    "    lesk_scores = {}\n",
    "    context_bag = lesk_context_bag(context_sentence, word)\n",
    "    for sense in wn.synsets(word):\n",
    "        count = 0\n",
    "        for w_gloss in sense.definition().split():\n",
    "            for w in context_bag:\n",
    "                if w==w_gloss:\n",
    "                    count += 1\n",
    "        lesk_scores[sense.name()] = count\n",
    "    return lesk_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the most Apt Sense of the Ambiguous word \n",
    "# Using Lesk Score as metric\n",
    "\n",
    "Give the word sense with highest Lesk score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk(context_sentence, word):\n",
    "    lesk_scores = compute_lesk_score(context_sentence, word)\n",
    "    max_ = 0\n",
    "    lesk_prediction = None\n",
    "    for s in lesk_scores:\n",
    "        if max_ < lesk_scores[s]:\n",
    "            lesk_prediction = s\n",
    "            max_ = lesk_scores[s]\n",
    "    \n",
    "    return lesk_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Lesk Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sentence is: Soham gets interest on his money from bank\n",
      " where the ambiguous word is bank \n",
      "\n",
      " The Predicted Sense is\n",
      "\n",
      " Sense name: depository_financial_institution.n.01\n",
      " Sense Gloss: a financial institution that accepts deposits and channels the money into lending activities\n"
     ]
    }
   ],
   "source": [
    "word = WordNetLemmatizer().lemmatize(PorterStemmer().stem(word=ambiguous_word))\n",
    "# print(word)\n",
    "sent = pre_process(sentence, porterstemmer=False)\n",
    "# print(sent)\n",
    "\n",
    "print(\"\\n Sentence is: {}\\n where the ambiguous word is {} \\n\". format(sentence, ambiguous_word))\n",
    "\n",
    "prediction = lesk(sent, word)\n",
    "w = wn.synset(prediction)\n",
    "print(\" The Predicted Sense is\\n\")\n",
    "print(\" Sense name: {}\\n Sense Gloss: {}\".format(w.name(), w.definition()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Walker Algorithm\n",
    "\n",
    "In this modified version of Walker Algorithm, we don't use thesaurus category. Instead we use similarity measures like path similarity, LCH similarity and WUP similarity. Refer Reference[1] for more details  \n",
    "\n",
    "## Algorithm:\n",
    "1. Find Context bag i.e concatenation of all words within the context\n",
    "2. For every sense of ambiguous word, find its similarity with every sense name of its context words via one of the techniques mentioned above. The sum of the cumulative scores is stored\n",
    "3. The Sense with maximum cumulative score is the desired sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_walker(sent, word, method = \"path_similarity\"):\n",
    "    max_ = 0\n",
    "    predicted = None\n",
    "    sent.remove(word)\n",
    "    for sense in wn.synsets(word):\n",
    "        score = 0\n",
    "        for w in sent:\n",
    "            for context_sense in wn.synsets(w):\n",
    "#                 print(sense.name(), context_sense.name())\n",
    "                try:\n",
    "                    if method == \"path_similarity\":\n",
    "                        score += wn.synset(sense.name()).path_similarity(wn.synset(context_sense.name()))\n",
    "                    elif method == \"lch_similarity\":\n",
    "                        score += wn.synset(sense.name()).lch_similarity(wn.synset(context_sense.name()))\n",
    "                    elif method == \"wup_similarity\":\n",
    "                        score += wn.synset(sense.name()).wup_similarity(wn.synset(context_sense.name()))\n",
    "                except:\n",
    "                    continue\n",
    "        if max_ < score:\n",
    "            max_ = score\n",
    "            predicted = sense\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Walkers algorithm\n",
    "The Algorithm works better with tagged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sentence is: Soham gets interest on his money from bank\n",
      " where the ambiguous word is bank \n",
      "\n",
      " The Predicted Sense is\n",
      "\n",
      " Sense name: bank.v.05\n",
      " Sense Gloss: be in the banking business\n"
     ]
    }
   ],
   "source": [
    "word = WordNetLemmatizer().lemmatize(PorterStemmer().stem(word=ambiguous_word))\n",
    "# print(word)\n",
    "sent = pre_process(sentence, porterstemmer=False)\n",
    "# print(sent)\n",
    "\n",
    "print(\"\\n Sentence is: {}\\n where the ambiguous word is {} \\n\". format(sentence, ambiguous_word))\n",
    "w = modified_walker(sent, word, method=\"wup_similarity\")\n",
    "print(\" The Predicted Sense is\\n\")\n",
    "print(\" Sense name: {}\\n Sense Gloss: {}\".format(w.name(), w.definition()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walk Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Context bag consisting of all senses of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk_context_bag_word(word):\n",
    "    context_bag_list = []\n",
    "    syn = wn.synset(word)\n",
    "    gloss = pre_process(str(syn.definition()))\n",
    "    for w_g in gloss:\n",
    "        context_bag_list.append(w_g)\n",
    "    return context_bag_list\n",
    "\n",
    "# lesk_context_bag(sent, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Lesk score comparing two words\n",
    "Get count of number of common words shared by the two words in their gloss bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lesk_score_word(word1, word2):\n",
    "    lesk_score = 0\n",
    "    context_bag_word1 = set(lesk_context_bag_word(word1))\n",
    "    context_bag_word2 = set(lesk_context_bag_word(word2))\n",
    "        \n",
    "    lesk_score = context_bag_word1.intersection(context_bag_word2)\n",
    "    \n",
    "    return len(lesk_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph for for the Random walk algorithm\n",
    "Add edges according to the lesk score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_graph(sentence):\n",
    "    G = nx.DiGraph()\n",
    "    sent_list = pre_process(sentence)\n",
    "#     print(sent_list)\n",
    "    for i in range(len(sent_list)-1):\n",
    "        w1 = sent_list[i]\n",
    "        w2 = sent_list[i+1]\n",
    "        for w1_sense in wn.synsets(w1):\n",
    "            for w2_sense in wn.synsets(w2):\n",
    "                lesk_score = compute_lesk_score_word(w1_sense.name(), w2_sense.name())\n",
    "                if lesk_score>0:\n",
    "                    G.add_edge(str(i)+'_'+w1_sense.name(), str(i+1)+ '_'+ w2_sense.name(), weight = lesk_score)\n",
    "    page_rank = nx.pagerank( G, alpha = 0.9)\n",
    "    return page_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final sense according to descending order of page rank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(sentence):\n",
    "    page_rank_scores = random_walk_graph(sentence)\n",
    "#     print(page_rank_scores)\n",
    "    sent_list = pre_process(sentence)\n",
    "    dict_pred_sense = {}\n",
    "    # initialise dictionary\n",
    "    for j in range(len(sent_list)):\n",
    "        dict_pred_sense[j+1] = [0,'null','sense']\n",
    "    for i in page_rank_scores:\n",
    "        t = int(i[0])\n",
    "        if page_rank_scores[i]>dict_pred_sense[t][0]:\n",
    "            dict_pred_sense[t][0] = page_rank_scores[i]\n",
    "            dict_pred_sense[t][1] = i\n",
    "            dict_pred_sense[t][2] = sent_list[t]\n",
    "    return dict_pred_sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence is: Soham gets interest on his money from bank\n",
      "\n",
      "Predicted Word Sense for functional words:\n",
      "\n",
      "The Sense for word 'get':\t get.v.01\n",
      "The definition is: come into the possession of something concrete or abstract\n",
      "\n",
      "The Sense for word 'interest':\t interest.n.05\n",
      "The definition is: (law) a right or legal share of something; a financial involvement with something\n",
      "\n",
      "The Sense for word 'money':\t money.n.01\n",
      "The definition is: the most common medium of exchange; functions as legal tender\n",
      "\n",
      "The Sense for word 'bank':\t bank.n.07\n",
      "The definition is: a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence is: {}\\n\".format(sentence))\n",
    "print(\"Predicted Word Sense for functional words:\")\n",
    "final_pgrnk = random_walk(sentence)\n",
    "for i in final_pgrnk:\n",
    "    if final_pgrnk[i][1]!='null':\n",
    "        word = final_pgrnk[i][1]\n",
    "        w_syn = wn.synset(word[2:])\n",
    "        print(\"\\nThe Sense for word '{}':\\t {}\\nThe definition is: {}\".format(final_pgrnk[i][2], w_syn.name(), w_syn.definition() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks\n",
    "## References\n",
    "\n",
    "[1] WordNet Interface. (2018). Nltk.org\n",
    "    Link: http://www.nltk.org/howto/wordnet.html\n",
    "    \n",
    "[2] NetworkX â€” NetworkX. (2018). Networkx.github.io \n",
    "    Link: https://networkx.github.io/documentation/networkx-1.10/overview.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
